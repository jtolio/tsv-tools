#!/usr/bin/env python3
#
# Copyright 2016 JT Olds
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

import os
import csv
import sys
import errno
import argparse
import itertools
from collections import defaultdict


class TSV(object):

  def __init__(self, fh):
    if isinstance(fh, str):
      fh = file(fh)
    self._lines = iter(fh)
    self._header = next(self._lines).rstrip("\r\n")
    self._lookup = defaultdict(list)
    for pos, name in enumerate(self._header.split("\t")):
      if name:
        self._lookup[name].append(pos)

  def __iter__(self):
    return self

  def __next__(self):
    fields = next(self._lines).rstrip("\r\n").split("\t")
    item = {}
    for i, field in enumerate(fields):
      item[i] = field
    for name, pos_list in self._lookup.items():
      filtered = [fields[pos] for pos in pos_list if pos < len(fields)]
      if not filtered: continue
      if len(filtered) == 1:
        item[name] = filtered[0]
      else:
        item[name] = filtered
    return item


def body(input):
  next(input)
  for line in input:
    print(line.rstrip("\r\n"))


def tocsv(input):
  out = csv.writer(sys.stdout)
  for line in input:
    out.writerow(line.rstrip("\r\n").split("\t"))


def fromcsv(input):
  for row in csv.reader(input):
    print("\t".join((x.replace("\t", " "*8) for x in row)))


def uniq(input):
  header = next(input).rstrip("\r\n")
  lines = [line.rstrip("\r\n") for line in input]
  lines.sort()
  last = None
  print(header)
  for line in lines:
    if line == last: continue
    last = line
    print(line)


def sum(input):
  header = next(input).rstrip("\r\n").split("\t")
  totals = [0.0] * len(header)
  print("\t".join(header))
  for row in input:
      row = row.rstrip("\r\n").split("\t")
      for i in range(len(row)):
          totals[i] += float(row[i])
  print("\t".join(map(str, totals)))


def cat(inputs, join):
  if not inputs: return

  headers = []
  lookups = []
  for input in inputs:
    field_counter = defaultdict(lambda: 0)
    header, lookup = [], {}
    for field in next(input).rstrip("\r\n").split("\t"):
      reference = (field, field_counter[field])
      field_counter[field] += 1
      lookup[reference] = len(header)
      header.append(reference)
    headers.append(tuple(header))
    lookups.append(lookup)

  if join in ("x", "exact"):
    chosen_header = headers[0]
    candidate = set(headers[0])
    for header in headers[1:]:
      if candidate != set(header):
        print("Error: headers do not match", file=sys.stderr)
        return 1

  elif join in ("i", "intersect", "intersection"):
    candidate = set(headers[0])
    for header in headers[1:]:
      candidate.intersection_update(set(header))

    if not candidate:
      print("Error: no overlapping columns", file=sys.stderr)
      return 0

    chosen_header = tuple(ref for ref in headers[0] if ref in candidate)

  else:
    assert join in ("u", "union")
    candidate = set()
    chosen_header = []
    for header in headers:
      for ref in header:
        if ref not in candidate:
          candidate.add(ref)
          chosen_header.append(ref)
    chosen_header = tuple(chosen_header)

  print("\t".join(field for field, _ in chosen_header))

  for i, input in enumerate(inputs):
    if headers[i] == chosen_header:
      for line in input:
        sys.stdout.write(line)
      continue

    for line in input:
      fields = line.rstrip("\r\n").split("\t")

      parts = []
      for reference in chosen_header:
        if reference in lookups[i] and lookups[i][reference] < len(fields):
          parts.append(fields[lookups[i][reference]])
        else:
          parts.append("")

      print("\t".join(parts))


def _get_header(input):
  header = next(input).rstrip("\r\n")

  lookup = defaultdict(list)
  for pos, name in enumerate(header.split("\t")):
    if name:
      lookup[name].append(pos)

  return header, lookup


def columns(input, columns):
  header, lookup = _get_header(input)

  names = []
  for column in columns:
    for _ in lookup[column]:
      names.append(column)

  print("\t".join(names))

  for line in input:
    fields = line.rstrip("\r\n").split("\t")

    parts = []
    for column in columns:
      for pos in lookup[column]:
        if pos < len(fields):
          parts.append(fields[pos])
        else:
          parts.append("")

    print("\t".join(parts))


def display(input, justify, initial_rows):
  max_widths = {}
  just = {"left": "ljust", "right": "rjust", "center": "center"}[justify]

  def process():
    for line in input:
      fields = line.rstrip("\r\n").split("\t")
      for field_id, field in enumerate(fields):
        max_widths[field_id] = max(max_widths.get(field_id, 0), len(field))
      yield fields

  processor = process()

  for fields in itertools.chain(
      list(itertools.islice(processor, initial_rows)), processor):
    print(" ".join((
        getattr(field, just)(max_widths[field_id])
        for field_id, field in enumerate(fields))))


def _numerical(cmp):
  def wrapped(x, y):
    try:
      int(x), int(y)
    except:
      pass
    else:
      return cmp(int(x), int(y))
    try:
      float(x), float(y)
    except:
      pass
    else:
      return cmp(float(x), float(y))
    return cmp(x, y)
  return wrapped


def _fileset(name, filename, _cache={}):
  if filename not in _cache:
    names = set()
    for line in file(filename):
      line = line.strip()
      if line: names.add(line)
    _cache[filename] = names
  return name in _cache[filename]


COMPARISONS = {
  "=": (_numerical(lambda x, y: x == y),
        "keep row if column x is equal to value y"),
  "==": (_numerical(lambda x, y: x == y),
        "keep row if column x is equal to value y"),
  "!=": (_numerical(lambda x, y: x != y),
        "keep row if column x is not equal to value y"),
  "<=": (_numerical(lambda x, y: x <= y),
        "keep row if column x is less than or equal to value y"),
  ">=": (_numerical(lambda x, y: x >= y),
        "keep row if column x is greater than or equal to value y"),
  "<": (_numerical(lambda x, y: x < y),
        "keep row if column x is less than value y"),
  ">": (_numerical(lambda x, y: x > y),
        "keep row if column x is greater than value y"),
  " in ": (_fileset,
        "keep row if column x is a line in the file y"),
  " not in ": (lambda x, y: not _fileset(x, y),
        "keep row if column x is not a line in the file y"),
  " contains ": (lambda x, y: y in x,
        "keep row if column x contains value y"),
  " not contains ": (lambda x, y: y not in x,
        "keep row if column x does not contain value y"),
  " starts with ": (lambda x, y: x.startswith(y),
        "keep row if column x starts with y"),
  " not starts with ": (lambda x, y: not x.startswith(y),
        "keep row if column x does not start with y"),
  " endswith ": (lambda x, y: x.endswith(y),
        "keep row if column x ends with y"),
  " not ends with ": (lambda x, y: not x.endswith(y),
        "keep row if column x does not end with y"),
}


def filter(input, selectors, case_insensitive):
  comparisons = list(sorted(list(COMPARISONS.keys()), key=len, reverse=True))

  selections = []
  for selector in selectors:
    found = False
    for comp in comparisons:
      if comp not in selector:
        continue
      key, val = selector.split(comp)
      if case_insensitive: val = val.lower()
      selections.append((key.strip(), COMPARISONS[comp][0], val.strip()))
      found = True
      break
    if not found:
      print("Error: unknown selector %r" % selector, file=sys.stderr)
      return 1

  header, lookup = _get_header(input)
  print(header)

  for line in input:
    line = line.rstrip("\r\n")
    fields = line.split("\t")
    good = True
    for key, comp, val in selections:
      for pos in lookup[key]:
        if pos >= len(fields):
          good = False
          break
        row_val = fields[pos].strip()
        if case_insensitive: row_val = row_val.lower()
        if not comp(row_val, val):
          good = False
          break
    if good:
      print(line)


def header(input):
  print(next(input).rstrip("\r\n"))


def sort(input, column, numeric, reverse):
  header, lookup = _get_header(input)
  print(header)

  rows = []
  for line in input:
    line = line.rstrip("\r\n")
    fields = line.split("\t")
    rows.append(fields)

  def row_key(row):
    indexes = lookup[column]
    if not indexes: return None
    key = row[indexes[0]]
    if numeric:
      key = float(key)
    return key

  rows.sort(key=row_key, reverse=reverse)

  for row in rows:
    print("\t".join(row))


def main():
  parser = argparse.ArgumentParser(prog="tsv")
  subparsers = parser.add_subparsers(help="subcommand", dest="subcommand")

  def pos_input(parser):
    parser.add_argument(
        "input", nargs="?", type=argparse.FileType("r"), default=sys.stdin,
        help="the path to read. if not provided, reads from stdin")

  def opt_input(parser):
    parser.add_argument(
        "-i", "--input", type=argparse.FileType("r"), default=sys.stdin,
        help="the path to read. if not provided, reads from stdin")

  parser_body = subparsers.add_parser("body",
      help="outputs all rows except for the header")
  pos_input(parser_body)

  parser_tocsv = subparsers.add_parser("tocsv",
      help="convert tsv input to a csv")
  pos_input(parser_tocsv)

  parser_fromcsv = subparsers.add_parser("fromcsv",
      help="convert a csv to tsv output")
  pos_input(parser_fromcsv)

  parser_cat = subparsers.add_parser("cat",
    help="concatenate multiple tsvs, joining intelligently based on headers")
  parser_cat.add_argument(
      "-j", "--join", choices=["x", "exact", "u", "union", "i", "intersect"],
      default="exact",
      help=("how to join two tables with different columns. x/exact will fail "
            "if the column headers don't match."))
  parser_cat.add_argument(
      "inputs", nargs="*", type=argparse.FileType("r"), default=[sys.stdin],
      metavar="input",
      help="the path(s) to read. if not provided, reads from stdin")

  parser_columns = subparsers.add_parser("columns",
      help="output a subset of columns")
  opt_input(parser_columns)
  parser_columns.add_argument(
      "columns", nargs="+", metavar="column", help="a column to output")

  parser_sort = subparsers.add_parser("sort",
      help="sort rows, respecting the header")
  opt_input(parser_sort)
  parser_sort.add_argument(
      "-n", "--numeric", action="store_true",
      help="whether or not to sort numerically")
  parser_sort.add_argument(
      "-r", "--reverse", action="store_true",
      help="whether or not to sort in reverse")
  parser_sort.add_argument("column", help="a column to sort by")

  parser_display = subparsers.add_parser(
      "display", help="print tsv data with nicely space-padded output",
      description=("nicely format tab-separated data without loading "
                   "everything into ram"))
  opt_input(parser_display)
  parser_display.add_argument(
      "-j", "--justify", choices=["left", "right", "center"], default="left",
      help="what kind of justification to apply to each column")
  parser_display.add_argument(
      "-r", "--initial-rows", type=int, metavar="rows",
      help="how much input to read before starting output", default=100)

  sellen = max(*list(map(len, list(COMPARISONS.keys())))) + len("  x  y:")
  parser_filter = subparsers.add_parser("filter",
      help="filter rows by a number of optional column selectors",
      formatter_class=argparse.RawDescriptionHelpFormatter,
      description=("possible selectors:\n" + "\n".join(
                   [("  x %s y:" % comp[0].strip()).ljust(sellen) + comp[1][1]
                    for comp in sorted(COMPARISONS.items())])))
  opt_input(parser_filter)
  parser_filter.add_argument(
      "-c", "--case-insensitive", action="store_true",
      help="whether or not filtering should happen case insensitively")
  parser_filter.add_argument(
      "selectors", metavar="selector", nargs="+",
      help="a constraint to filter the data with")

  parser_header = subparsers.add_parser("header",
      help="only display the tsv header")
  pos_input(parser_header)

  parser_uniq = subparsers.add_parser("uniq", help="only output unique rows")
  pos_input(parser_uniq)

  parser_sum = subparsers.add_parser("sum", help="add values in rows")
  pos_input(parser_sum)

  args = sys.argv[:]
  if os.path.basename(args[0]).startswith("tsv-"):
    args[0] = os.path.basename(args[0])[4:]
  else:
    args = args[1:]

  args = parser.parse_args(args).__dict__
  try:
    rv = globals()[args.pop("subcommand")](**args)
  except IOError as e:
    if e.errno != errno.EPIPE:
      raise
  else:
    if rv is not None:
      sys.exit(rv)


if __name__ == "__main__":
  main()
